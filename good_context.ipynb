{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24788239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import tbdb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefba40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_emotion_word(utterance, emotion_words):\n",
    "    # extract emotion words from the utterance according to our lists. \n",
    "    emotions_found = []\n",
    "    utterance = utterance.split()\n",
    "    for emotion in emotion_words:\n",
    "        if emotion in utterance:\n",
    "            emotions_found.append(emotion)\n",
    "    return emotions_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a57155",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import OpenAI\n",
    "client = ... # enter the keys here\n",
    "def label_row(row, word):\n",
    "    messages = [ {\"role\": \"system\", \"content\":  \n",
    "                  \"You are a intelligent assistant.\"} ] \n",
    "    message = f\"I am identifying what context the word {word} is being used by children. Please provide a one word label (don't give me a sentence) for the context in which {word} is used by the CHI (Child) in the last sentence. Emotion would be the label if it is being used in an emotion context. If not what is the context in one word?:\"+str(row)\n",
    "    if message: \n",
    "        messages.append( \n",
    "            {\"role\": \"user\", \"content\": message}, \n",
    "        ) \n",
    "        chat = client.chat.completions.create( \n",
    "            model=\"gpt-3.5-turbo\", messages=messages \n",
    "        ) \n",
    "    reply = chat.choices[0].message.content \n",
    "    #print(f\"ChatGPT: {reply}\") \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab95f79e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53a4998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5851a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luliu\\AppData\\Local\\Temp\\ipykernel_37312\\2327413080.py:1: DtypeWarning: Columns (0,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_utt_data = pd.read_csv('eng-NA-all-utterances.csv')\n"
     ]
    }
   ],
   "source": [
    "all_utt_data = pd.read_csv('eng-NA-all-utterances.csv')\n",
    "all_parts_data = pd.read_csv('eng-NA-all-participants.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b007e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emotion word lists\n",
    "final_emotion_list = ['happy', 'sad', 'afraid', 'angry', 'scared', 'surprised', 'excited', 'upset', 'glad', 'frightened', \\\n",
    "'unhappy', 'bored', 'lonely', 'annoyed', 'disappointed', 'ashamed', 'pleased', 'worried', 'calm', 'embarrassed', 'lonesome', \\\n",
    "'disgusted', 'cheerful', 'jealous', 'furious', 'delighted', 'unafraid', 'fed up', 'concerned', 'miserable', 'frustrated', \\\n",
    "'anxious', 'fearful', 'troubled', 'joyful', 'depressed', 'gloomy', 'merry', 'terrified', 'joyous', 'shocked', 'hopeful', \\\n",
    "'relieved', 'content', 'hopeless', 'carefree', 'envious', 'at ease', 'tense', 'mad', 'insecure', 'good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90d25bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_emotion_data = all_utt_data\n",
    "all_emotion_data[\"emotion_words\"] = all_emotion_data['utterance'].astype(str).apply(find_emotion_word, emotion_words=final_emotion_list)\n",
    "all_emotion_data = all_emotion_data[all_emotion_data['emotion_words'].apply(len) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5496b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the child participants\n",
    "child_part = all_parts_data[all_parts_data[\"who\"] == \"CHI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46b2c87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luliu\\AppData\\Local\\Temp\\ipykernel_37312\\1117228299.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  Laura = all_emotion_data[(all_emotion_data['path'].str.contains('Braunwald')) & (all_utt_data['who']=='CHI')]\n"
     ]
    }
   ],
   "source": [
    "# delete rows without emotion words\n",
    "Laura = all_emotion_data[(all_emotion_data['path'].str.contains('Braunwald')) & (all_utt_data['who']=='CHI')]\n",
    "Laura = Laura[Laura['emotion_words'].apply(len) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b002a82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n"
     ]
    }
   ],
   "source": [
    "# extract context for child Laura\n",
    "i = 0\n",
    "Laura['context'] = [[] for _ in range(len(Laura))]\n",
    "for index, row in Laura.iterrows():\n",
    "    i += 1\n",
    "    print(i)\n",
    "    # Find the subset of 'all_utt_data' DataFrame where the 'path' matches the current row's 'path'\n",
    "    matched_df = all_utt_data[all_utt_data['path'] == row['path']]\n",
    "    # Find the index of the row in 'matched_df' where 'utt_num' matches the current row's 'utt_num'\n",
    "    match_index = matched_df.index[matched_df['utt_num'] == row['utt_num']].tolist()\n",
    "    if match_index[0] > 0:\n",
    "        # Determine the starting index for context, 5 rows before the match_index\n",
    "        start_index = match_index[0] - 5\n",
    "        while start_index < 0:\n",
    "        # one row after \n",
    "            start_index += 1\n",
    "        context_rows = all_utt_data.iloc[start_index:match_index[0]+1]    \n",
    "    context_list = [f\"{row['who']}:{row['utterance']}\" for _, row in context_rows.iterrows()]\n",
    "    # Assign the 'context_list' to the 'context' column in 'Laura' for the current index\n",
    "    Laura.at[index, 'context'] = context_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a1438ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luliu\\AppData\\Local\\Temp\\ipykernel_6360\\2960699825.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  child_part.drop_duplicates(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "child_part.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78b77081",
   "metadata": {},
   "outputs": [],
   "source": [
    "Laura = pd.merge(Laura, child_part[['path', 'age']], on=['path'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "124c779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create age groups\n",
    "Laura['age'] = Laura['age'].str.replace(r'\\..*', '', regex=True)\n",
    "Laura[['years', 'months']] = Laura['age'].str.split(';', expand=True)\n",
    "Laura['years'] = pd.to_numeric(Laura['years'], errors='coerce')\n",
    "Laura['months'] = pd.to_numeric(Laura['months'], errors='coerce')\n",
    "Laura['months_decimal'] = round(Laura['months'] / 12, 2)\n",
    "Laura['decimal_age'] = Laura['years'] + Laura['months_decimal']\n",
    "Laura.drop(['years', 'months', 'months_decimal', 'age'], axis=1, inplace=True)\n",
    "Laura['age_group'] = Laura['decimal_age'].apply(lambda x: f\"{int(x)}-{int(x)+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff29fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b49215bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at utterances with emotion word good\n",
    "Laura_good = Laura[Laura['emotion_words'].apply(lambda x: 'good' in x)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddf6dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6463f826",
   "metadata": {},
   "outputs": [],
   "source": [
    "### label context in batch\n",
    "# Number of rows per batch\n",
    "batch_size = 10\n",
    "\n",
    "# Create batches and apply the labeling function\n",
    "batches = [Laura_good.iloc[i:i+batch_size] for i in range(0, len(Laura_good), batch_size)]\n",
    "labels = [batch['context'].apply(label_row, word='good') for batch in batches]\n",
    "\n",
    "# Flatten the list of lists\n",
    "labels_flat = [label for sublist in labels for label in sublist]\n",
    "\n",
    "# Assign labels back to the DataFrame\n",
    "Laura_good['label'] = labels_flat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe10fa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "Laura_good.to_csv('Laura_good.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2154a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "Laura_good = pd.read_csv('Laura_good.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "462c8db2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>filename</th>\n",
       "      <th>path</th>\n",
       "      <th>utt_num</th>\n",
       "      <th>who</th>\n",
       "      <th>role</th>\n",
       "      <th>postcodes</th>\n",
       "      <th>gems</th>\n",
       "      <th>utterance</th>\n",
       "      <th>startTime</th>\n",
       "      <th>endTime</th>\n",
       "      <th>emotion_words</th>\n",
       "      <th>context</th>\n",
       "      <th>decimal_age</th>\n",
       "      <th>age_group</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>010615</td>\n",
       "      <td>childes/Eng-NA/Braunwald/010615</td>\n",
       "      <td>227</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Target_Child</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>oh good</td>\n",
       "      <td>710.506</td>\n",
       "      <td>712.143</td>\n",
       "      <td>['good']</td>\n",
       "      <td>[\"MOT:you're bypassing the bowl in front of me...</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1-2</td>\n",
       "      <td>emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>010621</td>\n",
       "      <td>childes/Eng-NA/Braunwald/010621</td>\n",
       "      <td>108</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Target_Child</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good</td>\n",
       "      <td>223.494</td>\n",
       "      <td>224.028</td>\n",
       "      <td>['good']</td>\n",
       "      <td>[\"MOT:that's right\", 'CHI:Swww', 'CHI:Swww', '...</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1-2</td>\n",
       "      <td>approval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>010707</td>\n",
       "      <td>childes/Eng-NA/Braunwald/010707</td>\n",
       "      <td>259</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Target_Child</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good doggy</td>\n",
       "      <td>489.898</td>\n",
       "      <td>491.721</td>\n",
       "      <td>['good']</td>\n",
       "      <td>['MOT:maybe he is', \"SIS:Gwww isn't a kitty\", ...</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1-2</td>\n",
       "      <td>praise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>010707</td>\n",
       "      <td>childes/Eng-NA/Braunwald/010707</td>\n",
       "      <td>261</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Target_Child</td>\n",
       "      <td>SR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good doggy</td>\n",
       "      <td>492.382</td>\n",
       "      <td>494.136</td>\n",
       "      <td>['good']</td>\n",
       "      <td>['CHI:he more than you', \"SIS:you know Gwww is...</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1-2</td>\n",
       "      <td>emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>010707</td>\n",
       "      <td>childes/Eng-NA/Braunwald/010707</td>\n",
       "      <td>262</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Target_Child</td>\n",
       "      <td>SR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good doggy</td>\n",
       "      <td>494.321</td>\n",
       "      <td>496.248</td>\n",
       "      <td>['good']</td>\n",
       "      <td>[\"SIS:you know Gwww isn't a kitty\", 'CHI:yeah'...</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1-2</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>194</td>\n",
       "      <td>374</td>\n",
       "      <td>030301</td>\n",
       "      <td>childes/Eng-NA/Braunwald/0diary/030301</td>\n",
       "      <td>21</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Target_Child</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['good']</td>\n",
       "      <td>['MOT:I saved the house jobs for you', 'CHI:oh...</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3-4</td>\n",
       "      <td>approval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>376</td>\n",
       "      <td>030309</td>\n",
       "      <td>childes/Eng-NA/Braunwald/0diary/030309</td>\n",
       "      <td>1</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Target_Child</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>that's a good idea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['good']</td>\n",
       "      <td>['CHI:more cow cheese', 'MOT:okay here you go'...</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3-4</td>\n",
       "      <td>approval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>388</td>\n",
       "      <td>030406</td>\n",
       "      <td>childes/Eng-NA/Braunwald/0diary/030406</td>\n",
       "      <td>5</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Target_Child</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>could I lick this since I did a good job</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['good']</td>\n",
       "      <td>[\"CHI:Daddy I'm getting better at my letters\",...</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3-4</td>\n",
       "      <td>task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>394</td>\n",
       "      <td>030417</td>\n",
       "      <td>childes/Eng-NA/Braunwald/0diary/030417</td>\n",
       "      <td>10</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Target_Child</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>milk is good better than water Joanna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['good']</td>\n",
       "      <td>[\"CHI:I get the rest since I'm the nut server\"...</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3-4</td>\n",
       "      <td>preference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>396</td>\n",
       "      <td>030424</td>\n",
       "      <td>childes/Eng-NA/Braunwald/0diary/030424</td>\n",
       "      <td>4</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Target_Child</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm really a good eater huh Mama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['good']</td>\n",
       "      <td>['CHI:I forgot her name', \"CHI:that's enough f...</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3-4</td>\n",
       "      <td>capability</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  index filename                                    path  \\\n",
       "0             0      4   010615         childes/Eng-NA/Braunwald/010615   \n",
       "1             1      9   010621         childes/Eng-NA/Braunwald/010621   \n",
       "2             2     11   010707         childes/Eng-NA/Braunwald/010707   \n",
       "3             3     12   010707         childes/Eng-NA/Braunwald/010707   \n",
       "4             4     13   010707         childes/Eng-NA/Braunwald/010707   \n",
       "..          ...    ...      ...                                     ...   \n",
       "194         194    374   030301  childes/Eng-NA/Braunwald/0diary/030301   \n",
       "195         195    376   030309  childes/Eng-NA/Braunwald/0diary/030309   \n",
       "196         196    388   030406  childes/Eng-NA/Braunwald/0diary/030406   \n",
       "197         197    394   030417  childes/Eng-NA/Braunwald/0diary/030417   \n",
       "198         198    396   030424  childes/Eng-NA/Braunwald/0diary/030424   \n",
       "\n",
       "     utt_num  who          role postcodes  gems  \\\n",
       "0        227  CHI  Target_Child         I   NaN   \n",
       "1        108  CHI  Target_Child       NaN   NaN   \n",
       "2        259  CHI  Target_Child       NaN   NaN   \n",
       "3        261  CHI  Target_Child        SR   NaN   \n",
       "4        262  CHI  Target_Child        SR   NaN   \n",
       "..       ...  ...           ...       ...   ...   \n",
       "194       21  CHI  Target_Child       NaN   NaN   \n",
       "195        1  CHI  Target_Child       NaN   NaN   \n",
       "196        5  CHI  Target_Child       NaN   NaN   \n",
       "197       10  CHI  Target_Child       NaN   NaN   \n",
       "198        4  CHI  Target_Child       NaN   NaN   \n",
       "\n",
       "                                    utterance  startTime  endTime  \\\n",
       "0                                     oh good    710.506  712.143   \n",
       "1                                        good    223.494  224.028   \n",
       "2                                  good doggy    489.898  491.721   \n",
       "3                                  good doggy    492.382  494.136   \n",
       "4                                  good doggy    494.321  496.248   \n",
       "..                                        ...        ...      ...   \n",
       "194                                      good        NaN      NaN   \n",
       "195                        that's a good idea        NaN      NaN   \n",
       "196  could I lick this since I did a good job        NaN      NaN   \n",
       "197     milk is good better than water Joanna        NaN      NaN   \n",
       "198          I'm really a good eater huh Mama        NaN      NaN   \n",
       "\n",
       "    emotion_words                                            context  \\\n",
       "0        ['good']  [\"MOT:you're bypassing the bowl in front of me...   \n",
       "1        ['good']  [\"MOT:that's right\", 'CHI:Swww', 'CHI:Swww', '...   \n",
       "2        ['good']  ['MOT:maybe he is', \"SIS:Gwww isn't a kitty\", ...   \n",
       "3        ['good']  ['CHI:he more than you', \"SIS:you know Gwww is...   \n",
       "4        ['good']  [\"SIS:you know Gwww isn't a kitty\", 'CHI:yeah'...   \n",
       "..            ...                                                ...   \n",
       "194      ['good']  ['MOT:I saved the house jobs for you', 'CHI:oh...   \n",
       "195      ['good']  ['CHI:more cow cheese', 'MOT:okay here you go'...   \n",
       "196      ['good']  [\"CHI:Daddy I'm getting better at my letters\",...   \n",
       "197      ['good']  [\"CHI:I get the rest since I'm the nut server\"...   \n",
       "198      ['good']  ['CHI:I forgot her name', \"CHI:that's enough f...   \n",
       "\n",
       "     decimal_age age_group       label  \n",
       "0           1.50       1-2     emotion  \n",
       "1           1.50       1-2    approval  \n",
       "2           1.58       1-2      praise  \n",
       "3           1.58       1-2     emotion  \n",
       "4           1.58       1-2   affection  \n",
       "..           ...       ...         ...  \n",
       "194         3.25       3-4    approval  \n",
       "195         3.25       3-4    approval  \n",
       "196         3.33       3-4        task  \n",
       "197         3.33       3-4  preference  \n",
       "198         3.33       3-4  capability  \n",
       "\n",
       "[199 rows x 17 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Laura_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d398b6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_lst = list(Laura_good['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3a27ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any potential punctuation generated by openai reponse\n",
    "import string\n",
    "for i in range(len(label_lst)):\n",
    "    label_lst[i] = label_lst[i].lower().strip(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01309d4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['care',\n",
       " 'happiness',\n",
       " 'unclear',\n",
       " 'emotion',\n",
       " 'greeting',\n",
       " 'judgment',\n",
       " 'taste',\n",
       " 'desire',\n",
       " 'skill',\n",
       " 'action',\n",
       " 'family',\n",
       " 'behavior',\n",
       " 'capability',\n",
       " 'desirability',\n",
       " 'health',\n",
       " 'encouragement',\n",
       " 'repetition',\n",
       " 'preference',\n",
       " 'appreciation',\n",
       " 'evaluation',\n",
       " 'animals',\n",
       " 'wishful',\n",
       " 'ability',\n",
       " 'food',\n",
       " 'affection',\n",
       " 'possession',\n",
       " 'compliance',\n",
       " 'interaction',\n",
       " 'response',\n",
       " 'approval',\n",
       " 'manners',\n",
       " 'sound',\n",
       " 'character',\n",
       " 'beneficial',\n",
       " 'wish',\n",
       " 'enjoyment',\n",
       " 'relationship',\n",
       " 'task',\n",
       " 'comparison',\n",
       " 'achievement',\n",
       " 'opinion',\n",
       " 'positive',\n",
       " 'approbation',\n",
       " 'certainty',\n",
       " 'praise',\n",
       " 'accomplishment',\n",
       " 'quality',\n",
       " 'satisfaction']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_lst = list(set(label_lst))\n",
    "label_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75aaa8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any punctuation\n",
    "Laura_good['label'] = Laura_good['label'].str.lower().str.rstrip('.!?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be08fb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract one example for each unique label\n",
    "first_rows = []\n",
    "for label in label_lst:\n",
    "    match = Laura_good[Laura_good['label'].str.lower().str.rstrip('.!?') == label].head(1)\n",
    "    if not match.empty:\n",
    "        first_rows.append(match)\n",
    "laura_good_unique = pd.concat(first_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89665bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "laura_good_unique.to_csv('laura_good_unique.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ededb58f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3ace9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9f1e84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
