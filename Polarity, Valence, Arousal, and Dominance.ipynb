{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcb6b6f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Finding Polarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fee0dd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e828f6cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "001162dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f096e727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e828375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/tvidyala/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f699283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24094805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_column(file_path, row_start, row_end):\n",
    "    data = []\n",
    "    rowcount = 0\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            if rowcount >= row_start and rowcount < row_end:\n",
    "                if len(row) > 7:\n",
    "                    data.append(row[7]) # column 7 is the column for utterances\n",
    "                    rowcount += 1\n",
    "            elif rowcount >= row_end:\n",
    "                break\n",
    "            else: \n",
    "                rowcount+= 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1b43d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_csv_column(\"/Users/tvidyala/Desktop/CHILDES/eng-NA-all-utterances.csv\", 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b50ad17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wanna stack them for me\n",
      "[{'label': 'NEGATIVE', 'score': 0.9948791265487671}]\n",
      "\n",
      "that baby\n",
      "[{'label': 'POSITIVE', 'score': 0.9981951117515564}]\n",
      "\n",
      "oh\n",
      "[{'label': 'POSITIVE', 'score': 0.9806591272354126}]\n",
      "\n",
      "did you say baby\n",
      "[{'label': 'POSITIVE', 'score': 0.7280847430229187}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "data = data\n",
    "for item in data:\n",
    "    print(item)\n",
    "    print(f\"{sentiment_pipeline(item)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "275aaeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wanna stack them for me\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "that baby\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "oh\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "did you say baby\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "data = data \n",
    "for item in data:\n",
    "    print(item)\n",
    "    print(f\"{analyzer.polarity_scores(item)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3668b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel happy\n",
      "[{'label': 'POSITIVE', 'score': 0.999883770942688}]\n",
      "\n",
      "{'neg': 0.0, 'neu': 0.213, 'pos': 0.787, 'compound': 0.5719}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "data = [\"i feel happy\"] #insert data here \n",
    "for item in data:\n",
    "    print(item)\n",
    "    print(f\"{sentiment_pipeline(item)}\\n\")\n",
    "    print(f\"{analyzer.polarity_scores(item)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424dac7a-5c0f-4ae6-a882-2094d07ba827",
   "metadata": {},
   "source": [
    "# Finding Valence, Arousal, and Dominance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18ba02e2-4b1f-4782-8a30-90cc5c25f52c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install stanfordnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fbd1d12-f706-4dc0-83bf-a95fbfd97883",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "MOT: \"yeah\"\n",
      "N/A \n",
      "\n",
      "2\n",
      "MOT: \"this is July thirtieth\"\n",
      "N/A \n",
      "\n",
      "3\n",
      "CHI: \"go\"\n",
      "valence      0.510\n",
      "arousal      0.441\n",
      "dominance    0.444\n",
      "Name: go, dtype: float64\n",
      "\n",
      "4\n",
      "MOT: \"that's the recorder\"\n",
      "valence      0.551\n",
      "arousal      0.374\n",
      "dominance    0.481\n",
      "Name: recorder, dtype: float64\n",
      "\n",
      "5\n",
      "MOT: \"that's correct\"\n",
      "valence      0.857\n",
      "arousal      0.306\n",
      "dominance    0.723\n",
      "Name: correct, dtype: float64\n",
      "\n",
      "6\n",
      "MOT: \"day day day day day day day day day day day\"\n",
      "valence      0.719\n",
      "arousal      0.269\n",
      "dominance    0.389\n",
      "Name: day, dtype: float64\n",
      "\n",
      "7\n",
      "CHI: \"be\"\n",
      "valence      0.670\n",
      "arousal      0.240\n",
      "dominance    0.554\n",
      "Name: be, dtype: float64\n",
      "\n",
      "8\n",
      "MOT: \"be what\"\n",
      "valence      0.670\n",
      "arousal      0.240\n",
      "dominance    0.554\n",
      "Name: be, dtype: float64\n",
      "\n",
      "9\n",
      "CHI: \"Shower\"\n",
      "N/A \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ym/3kwq9dtj5914fkc699t0n4980000gn/T/ipykernel_72873/3612244237.py:19: RuntimeWarning: invalid value encountered in divide\n",
      "  return text_vad / i\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# utterances by age, column, put all into one csv file\n",
    "\n",
    "def VAD(text, vad_scores):\n",
    "    i, j = 0, 0\n",
    "    text_vad = np.zeros([3,])\n",
    "    for word in text.split(' '):\n",
    "        neg = 1  # reverse polarity for this word\n",
    "        if word in vad_scores.index:\n",
    "            if 'no' in text.split(' ')[max(0, j-6):j] or 'not' in text.split(' ')[max(0, j-6):j] or 'n\\'t' in str(text.split(' ')[max(0, j-3):j]):\n",
    "                neg = -1\n",
    "            text_vad = vad_scores.loc[word] * neg + text_vad\n",
    "            i += 1\n",
    "        j += 1\n",
    "    return text_vad / i\n",
    "\n",
    "def read_csv_column(file_path, row_start, row_end, column_index):\n",
    "    data = []\n",
    "    rowcount = 0\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            if rowcount >= row_start and rowcount < row_end:\n",
    "                if len(row) > column_index:\n",
    "                    data.append(row[column_index])\n",
    "                rowcount += 1\n",
    "            elif rowcount >= row_end:\n",
    "                break\n",
    "            else: \n",
    "                rowcount += 1\n",
    "    return data\n",
    "\n",
    "# Read child's data from CSV file\n",
    "data = read_csv_column(\"/Users/tvidyala/Desktop/CHILDES/Laura.csv\", 1, 10, 8) \n",
    "speaker_data = read_csv_column(\"/Users/tvidyala/Desktop/CHILDES/Laura.csv\", 1, 10, 4) \n",
    "filename_data = read_csv_column(\"/Users/tvidyala/Desktop/CHILDES/Laura.csv\", 1, 10, 0)\n",
    "\n",
    "# Load VAD scores\n",
    "vad_scores = pd.read_csv(\"vad-nrc.csv\", index_col='Word')\n",
    "\n",
    "# Calculate VAD scores for each CHILD utterance\n",
    "for text in data:\n",
    "    vad = VAD(text, vad_scores)\n",
    "    print(data.index(text)+1)\n",
    "    print(f'{speaker_data[data.index(text)]}: \"{text}\"')\n",
    "    if np.isnan(vad).any():\n",
    "        print(\"N/A \\n\")\n",
    "    else:\n",
    "        print(vad)\n",
    "        print(\"\")\n",
    "        \n",
    "arousal_scores = []\n",
    "valence_scores = []\n",
    "dominance_scores = []\n",
    "\n",
    "for text in data:\n",
    "    vad = VAD(text, vad_scores)\n",
    "    arousal_scores.append(vad[0])\n",
    "    valence_scores.append(vad[1])\n",
    "    dominance_scores.append(vad[2])\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'File Name': filename_data,\n",
    "    'Utterance': data,\n",
    "    'Speaker': speaker_data,\n",
    "    'Arousal': arousal_scores,\n",
    "    'Valence': valence_scores,\n",
    "    'Dominance': dominance_scores\n",
    "})\n",
    "\n",
    "df.to_csv(\"/Users/tvidyala/Desktop/CHILDES/LauraVADScores.csv\", index=False) # updates LauraVADScores with VAD Scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76538f1-f3b5-4e9b-aa7f-c55299301e40",
   "metadata": {},
   "source": [
    "# Finding Average Valence, Arousal, and Dominance for Child by Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59f92669-a6b5-4ff7-95af-a95b21e16712",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average VAD scores for Child's Utterances at 1 year(s) and 5 month(s)\n",
      "Valence: 0.4869333333333333\n",
      "Arousal: 0.43606666666666677\n",
      "Dominance: 0.3637333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ym/3kwq9dtj5914fkc699t0n4980000gn/T/ipykernel_29386/1543044282.py:17: RuntimeWarning: invalid value encountered in divide\n",
      "  return text_vad / i\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "def VAD(text, vad_scores):\n",
    "    i, j = 0, 0\n",
    "    text_vad = np.zeros([3,])\n",
    "    for word in text.split(' '):\n",
    "        neg = 1  # reverse polarity for this word\n",
    "        if word in vad_scores.index:\n",
    "            if 'no' in text.split(' ')[max(0, j-6):j] or 'not' in text.split(' ')[max(0, j-6):j] or 'n\\'t' in str(text.split(' ')[max(0, j-3):j]):\n",
    "                neg = -1\n",
    "            text_vad = vad_scores.loc[word] * neg + text_vad\n",
    "            i += 1\n",
    "        j += 1\n",
    "    return text_vad / i\n",
    "\n",
    "def read_csv_column(file_path, row_start, row_end, column_index):\n",
    "    data = []\n",
    "    rowcount = 0\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            if rowcount >= row_start and rowcount < row_end:\n",
    "                if len(row) > column_index:\n",
    "                    data.append(row[column_index])\n",
    "                rowcount += 1\n",
    "            elif rowcount >= row_end:\n",
    "                break\n",
    "            else: \n",
    "                rowcount += 1\n",
    "    return data\n",
    "\n",
    "# Read child's data from CSV file\n",
    "data = read_csv_column(\"/Users/tvidyala/Desktop/CHILDES/Laura.csv\", 1, 100, 8)  # Assuming column 7 contains utterances\n",
    "speaker_data = read_csv_column(\"/Users/tvidyala/Desktop/CHILDES/Laura.csv\", 1, 100, 4)  # Assuming column 3 contains speaker data\n",
    "age_data = read_csv_column(\"/Users/tvidyala/Desktop/CHILDES/Laura.csv\", 1, 100, 1)  # Assuming column 11 contains age data\n",
    "\n",
    "# Load VAD scores\n",
    "vad_scores = pd.read_csv(\"vad-nrc.csv\", index_col='Word')\n",
    "\n",
    "# Initialize variables to accumulate VAD scores\n",
    "total_vad = np.zeros([3,])\n",
    "valid_utterances = 0\n",
    "\n",
    "# Calculate VAD scores for each CHILD utterance and accumulate\n",
    "\n",
    "age = \"105\" # first number is age in years, second two numbers are number of months (01, 02, 03... 10, 11)\n",
    "for text in data:\n",
    "    if int(age) == int(age_data[data.index(text)][:3]): # fix this  \n",
    "        vad = VAD(text, vad_scores)\n",
    "        if speaker_data[data.index(text)] == \"CHI\":\n",
    "            if not np.isnan(vad).any():\n",
    "                total_vad += vad\n",
    "                valid_utterances += 1\n",
    "\n",
    "# Calculate the average VAD scores\n",
    "average_vad = total_vad / valid_utterances\n",
    "\n",
    "if age[1] == \"0\":\n",
    "    print(f\"Average VAD scores for Child's Utterances at {age[0]} year(s) and {age[2]} month(s)\")\n",
    "    print(\"Valence:\", average_vad[0])\n",
    "    print(\"Arousal:\", average_vad[1])\n",
    "    print(\"Dominance:\", average_vad[2])\n",
    "else: \n",
    "    print(f\"Average VAD scores for Child's Utterances at {age[0]} year(s) and {age[1]+age[2]} month(s)\")\n",
    "    print(\"Valence:\", average_vad[0])\n",
    "    print(\"Arousal:\", average_vad[1])\n",
    "    print(\"Dominance:\", average_vad[2])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24d404b-c6ec-4122-a1a0-3974b9ffdb22",
   "metadata": {},
   "source": [
    "next steps figure out how to put it into csv file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
